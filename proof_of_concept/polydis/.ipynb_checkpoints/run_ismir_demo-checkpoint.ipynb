{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "from model import DisentangleVAE\n",
    "from dataset_loaders import MusicDataLoaders, TrainingVAE\n",
    "from dataset import SEED\n",
    "import torch\n",
    "import amc_dl.demo_maker as demo_maker\n",
    "from collect_song import SongDatasets\n",
    "import os\n",
    "import mir_eval\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder contains 886 .npz files.\n",
      "Selected 858 files, all are in duple meter.\n",
      "705216 7513\n"
     ]
    }
   ],
   "source": [
    "demo_seed = 1234\n",
    "torch.manual_seed(demo_seed)\n",
    "model_path = 'result/models/disvae-nozoth_epoch.pt'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DisentangleVAE.init_model(device)\n",
    "model.load_model(model_path, map_location=device)\n",
    "bpm = 80\n",
    "batch_size = 16\n",
    "data_loaders = \\\n",
    "    MusicDataLoaders.get_loaders(SEED, bs_train=batch_size, bs_val=batch_size,\n",
    "                                 portion=8, shift_low=-6, shift_high=5,\n",
    "                                 num_bar=2,\n",
    "                                 contain_chord=True, random_train=True,\n",
    "                                 random_val=True)\n",
    "song_datasets = SongDatasets(data_loaders.train_loader.dataset,\n",
    "                             data_loaders.val_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outs_to_demo(out, bpm=80):\n",
    "    _, notes = model.decoder.grid_to_pr_and_notes(out, bpm=bpm)\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listen to Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_ground_truth(folder):\n",
    "    outs = []\n",
    "    msgs = []\n",
    "    for song_id in range(len(song_datasets.song_dataset_v.song_ind)):\n",
    "        msg = song_datasets.get_msg(1, song_id, None, 0)\n",
    "        batch = song_datasets.get_song_batch(1, song_id, None, 0)\n",
    "        x, _, _, _ = data_loaders.batch_to_inputs(batch)\n",
    "        out = model.gt_sample(x)\n",
    "        outs.append(out)\n",
    "        msgs.append(msg)\n",
    "    track_notes = demo_maker.demo_format_convert(outs, outs_to_demo, bpm)\n",
    "    fn = os.path.join(folder, 'gt_val_samples.mid')\n",
    "    track_names = msgs\n",
    "    demo_maker.write_demo(fn, track_notes, track_names, bpm, shift_beat=8)\n",
    "    print('gt done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_ground_truth(folder):\n",
    "    outs = []\n",
    "    msgs = []\n",
    "    num_sample = 20\n",
    "    count = 0\n",
    "    for song_id in range(len(song_datasets.song_dataset_t.song_ind)):\n",
    "        msg = song_datasets.get_msg(0, song_id, None, 0)\n",
    "        batch = song_datasets.get_song_batch(0, song_id, None, 0)\n",
    "        x, _, _, _ = data_loaders.batch_to_inputs(batch)\n",
    "        out = model.gt_sample(x)\n",
    "        outs.append(out)\n",
    "        msgs.append(msg)\n",
    "        if song_id % num_sample == num_sample - 1 or \\\n",
    "            song_id == len(song_datasets.song_dataset_t.song_ind) - 1:\n",
    "            track_notes = demo_maker.demo_format_convert(outs, outs_to_demo, bpm)\n",
    "            fn = os.path.join(folder, 'gt_train_samples_part_%d.mid' % count)\n",
    "            track_names = msgs\n",
    "            demo_maker.write_demo(fn, track_notes, track_names, bpm, shift_beat=8)\n",
    "            count += 1\n",
    "            outs = []\n",
    "            msgs = []\n",
    "    print('gt done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_path = 'ismir_demo_0509'\n",
    "if not os.path.exists(demo_path):\n",
    "    os.mkdir(demo_path)\n",
    "gt_long_path = os.path.join(demo_path, 'gt_long')\n",
    "if not os.path.exists(gt_long_path):\n",
    "    os.mkdir(gt_long_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt done\n"
     ]
    }
   ],
   "source": [
    "get_val_ground_truth(gt_long_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt done\n"
     ]
    }
   ],
   "source": [
    "get_train_ground_truth(gt_long_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Long Swap Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_song(dataset_id1, song_id1, length1, shift1, \n",
    "              dataset_id2, song_id2, length2, shift2,\n",
    "              folder=None):\n",
    "    length1 = song_datasets.valid_length(dataset_id1, song_id1, length1)\n",
    "    length2 = song_datasets.valid_length(dataset_id2, song_id2, length2)\n",
    "    info = '-'.join([song_datasets.get_msg(dataset_id1, song_id1, length1, shift1), \n",
    "                     song_datasets.get_msg(dataset_id2, song_id2, length2, shift2)])\n",
    "    length = min(length1, length2)\n",
    "    print(length)\n",
    "    batch1 = song_datasets.get_song_batch(dataset_id1, song_id1, length, shift1)\n",
    "    batch2 = song_datasets.get_song_batch(dataset_id2, song_id2, length, shift2)\n",
    "    x1, c1, pr_mat1, dt_x1 = data_loaders.batch_to_inputs(batch1)\n",
    "    x2, c2, pr_mat2, dt_x2 = data_loaders.batch_to_inputs(batch2)\n",
    "    print(x1.size(), c1.size(), pr_mat1.size())\n",
    "    print(x2.size(), c2.size(), pr_mat2.size())\n",
    "    out11 = model.gt_sample(x1)\n",
    "    out12 = model.swap(pr_mat1, pr_mat2, c1, c2,\n",
    "                       fix_rhy=True, fix_chd=False)\n",
    "    out21 = model.swap(pr_mat1, pr_mat2, c1, c2,\n",
    "                       fix_rhy=False, fix_chd=True)\n",
    "    out22 = model.gt_sample(x2)\n",
    "    oo = [out11, out22, out12, out21]\n",
    "    demo_folder = os.path.join(folder, info)\n",
    "    if not os.path.exists(demo_folder):\n",
    "        os.mkdir(demo_folder)\n",
    "    track_notes = demo_maker.demo_format_convert(oo, outs_to_demo, bpm)\n",
    "    fn = os.path.join(folder, 'swap-' + info + '.mid')\n",
    "    track_names = ['a', 'b', 'swap_chord', 'swap_rhy']\n",
    "    demo_maker.write_demo(fn, track_notes, track_names, bpm, shift_beat=8)\n",
    "    fn = os.path.join(demo_folder, 'all.mid')\n",
    "    track_names = ['a', 'b', 'swap_chord', 'swap_rhy']\n",
    "    demo_maker.write_demo(fn, track_notes, track_names, bpm, shift_beat=8)\n",
    "    for name, track in zip(track_names, oo):\n",
    "        track_notes = demo_maker.demo_format_convert([track], outs_to_demo, bpm)\n",
    "        fn = os.path.join(demo_folder, name + '.mid')\n",
    "        track_names = ['sample']\n",
    "        demo_maker.write_demo(fn, track_notes, track_names, bpm, shift_beat=8)\n",
    "    \n",
    "    print('swap done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_chord(dataset_id, song_id, length, shift):\n",
    "    length = song_datasets.valid_length(dataset_id, song_id, length)\n",
    "    info = song_datasets.get_msg(dataset_id, song_id, length, shift)\n",
    "    batch = song_datasets.get_song_batch(dataset_id, song_id, length, shift)\n",
    "    x, c, pr_mat, dt_x = data_loaders.batch_to_inputs(batch)\n",
    "    print('chord info of %s' % info)\n",
    "    for i, chord in enumerate(c):\n",
    "        print('===== segment %d =====' % i)\n",
    "        for cc in chord:\n",
    "            root = cc[0: 12].argmax()\n",
    "            chroma = cc[12: 24]\n",
    "            bass = cc[24:].argmax()\n",
    "            print(root.item(), bass.item())\n",
    "            print(' ', chroma.numpy())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_path = 'ismir_demo_0509'\n",
    "if not os.path.exists(demo_path):\n",
    "    os.mkdir(demo_path)\n",
    "swap_long_path = os.path.join(demo_path, 'swap_long')\n",
    "if not os.path.exists(swap_long_path):\n",
    "    os.mkdir(swap_long_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "torch.Size([8, 32, 16, 6]) torch.Size([8, 8, 36]) torch.Size([8, 32, 128])\n",
      "torch.Size([8, 32, 16, 6]) torch.Size([8, 8, 36]) torch.Size([8, 32, 128])\n",
      "swap done\n"
     ]
    }
   ],
   "source": [
    "song1 = [1, 84, 16, 0]\n",
    "song2 = [1, 122, 16, 6]\n",
    "song3 = [1, 3, 16, 0]\n",
    "song4 = [1, 21, 47, 0]\n",
    "song5 = [1, 122, 16, 0]\n",
    "song6 = [1, 31, 16, 17]  # rigid acc. Mel.\n",
    "song6 = [1, 31, 16, 18]  # rigid acc. Mel.\n",
    "song7 = [1, 26, 16, 18]  # bomqia\n",
    "song8 = [1, 80, 16, 2]  # transpose\n",
    "song9 = [1, 111, 16, 7]  # C major\n",
    "song10 = [1, 84, 16, 8]\n",
    "song11 = [1, 63, 16, 35]  # minge\n",
    "\n",
    "song12 = [1, 3, 25, 1]\n",
    "song13 = [1, 63, 16, 36]\n",
    "swap_song(*song8, *song10, swap_long_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chord info of 1_3_16_0\n",
      "===== segment 0 =====\n",
      "9 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "9 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "11 0\n",
      "  [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "11 0\n",
      "  [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "8 0\n",
      "  [1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "8 0\n",
      "  [1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "1 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "1 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "===== segment 1 =====\n",
      "9 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "9 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "11 0\n",
      "  [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "11 0\n",
      "  [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "4 0\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1.]\n",
      "4 0\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1.]\n",
      "8 0\n",
      "  [1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "8 0\n",
      "  [1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "===== segment 2 =====\n",
      "6 0\n",
      "  [0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      "6 0\n",
      "  [0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      "6 0\n",
      "  [0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      "6 0\n",
      "  [0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      "1 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "1 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "1 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "1 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "===== segment 3 =====\n",
      "9 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "9 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "9 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "9 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "8 0\n",
      "  [1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "8 0\n",
      "  [1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "8 0\n",
      "  [1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "8 0\n",
      "  [1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "===== segment 4 =====\n",
      "1 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "1 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "8 0\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "8 0\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "9 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "11 0\n",
      "  [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "4 0\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1.]\n",
      "4 0\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1.]\n",
      "===== segment 5 =====\n",
      "6 0\n",
      "  [0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      "6 0\n",
      "  [0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      "1 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "1 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "9 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "9 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "8 0\n",
      "  [1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "8 0\n",
      "  [1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "===== segment 6 =====\n",
      "1 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "1 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "8 0\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "8 0\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "9 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "11 0\n",
      "  [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "4 0\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1.]\n",
      "4 0\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1.]\n",
      "===== segment 7 =====\n",
      "6 0\n",
      "  [0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      "6 0\n",
      "  [0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      "1 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "1 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "9 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "9 0\n",
      "  [0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "8 0\n",
      "  [1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "8 0\n",
      "  [1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print_chord(*song3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Posterior Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_sample_song(dataset_id, song_id, length, shift, folder=None):\n",
    "    length = song_datasets.valid_length(dataset_id, song_id, length)\n",
    "    info = song_datasets.get_msg(dataset_id, song_id, length, shift)\n",
    "    batch = song_datasets.get_song_batch(dataset_id, song_id, length, shift)\n",
    "    x, c, pr_mat, dt_x = data_loaders.batch_to_inputs(batch)\n",
    "    out1 = model.gt_sample(x)\n",
    "    out2 = model.posterior_sample(pr_mat, c, 3, sample_chd=False, sample_txt=True)\n",
    "    out3 = model.posterior_sample(pr_mat, c, 3, sample_chd=False, sample_txt=True)\n",
    "    out4 = model.posterior_sample(pr_mat, c, 3, sample_chd=False, sample_txt=True)\n",
    "    out5 = model.posterior_sample(pr_mat, c, 5, sample_chd=True, sample_txt=False)\n",
    "    out6 = model.posterior_sample(pr_mat, c, 5, sample_chd=True, sample_txt=False)\n",
    "    out7 = model.posterior_sample(pr_mat, c, 5, sample_chd=True, sample_txt=False)\n",
    "    oo = [out1, out2, out3, out4, out5, out6, out7]\n",
    "    track_notes = demo_maker.demo_format_convert(oo, outs_to_demo, bpm)\n",
    "    fn = os.path.join(folder, 'postsample-' + info + '.mid')\n",
    "    track_names = ['gt', \n",
    "                   'post_sample_txt1', 'post_sample_txt2', 'post_sample_txt3',\n",
    "                   'post_sample_chd1', 'post_sample_chd2', 'post_sample_chd3']\n",
    "    demo_maker.write_demo(fn, track_notes, track_names, bpm, shift_beat=8)\n",
    "    \n",
    "    demo_folder = os.path.join(folder, info)\n",
    "    if not os.path.exists(demo_folder):\n",
    "        os.mkdir(demo_folder)\n",
    "    \n",
    "    fn = os.path.join(demo_folder, 'all.mid')\n",
    "    demo_maker.write_demo(fn, track_notes, track_names, bpm, shift_beat=8)\n",
    "    for name, track in zip(track_names, oo):\n",
    "        track_notes = demo_maker.demo_format_convert([track], outs_to_demo, bpm)\n",
    "        fn = os.path.join(demo_folder, name + '.mid')\n",
    "        track_names = ['sample']\n",
    "        demo_maker.write_demo(fn, track_notes, track_names, bpm, shift_beat=8)\n",
    "    print('post done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_long_path = os.path.join(demo_path, 'post_long')\n",
    "if not os.path.exists(post_long_path):\n",
    "    os.mkdir(post_long_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post done\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "post_sample_song(*song2, post_long_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3postsample-1_3_16_0.mid` is the best. First sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior texture experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chord_label_to_input(chords):\n",
    "    inputs = []\n",
    "    for c in chords:\n",
    "        chord = mir_eval.chord.encode(c, reduce_extended_chords=True)\n",
    "        root = chord[0]\n",
    "        chroma = np.roll(chord[1], root)\n",
    "        bass = chord[2] % 12\n",
    "        root_onehot = np.zeros(12)\n",
    "        root_onehot[int(root)] = 1\n",
    "        bass_onehot = np.zeros(12)\n",
    "        bass_onehot[int(bass)] = 1\n",
    "        inputs.append(np.concatenate([root_onehot, chroma, bass_onehot]))\n",
    "    return np.array(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_sample_song(dataset_id, song_id, length, shift, chord, bs=8, folder=None,\n",
    "                      chd_str=None):\n",
    "    length = song_datasets.valid_length(dataset_id, song_id, length)\n",
    "    info = chd_str + '-' + song_datasets.get_msg(dataset_id, song_id, length, shift)\n",
    "    batch = song_datasets.get_song_batch(dataset_id, song_id, length, shift)\n",
    "    x, c, pr_mat, dt_x = data_loaders.batch_to_inputs(batch)\n",
    "    c = torch.from_numpy(chord_label_to_input(chord)).unsqueeze(0).repeat(bs, 1, 1).float()\n",
    "    pr_mat = pr_mat[0: bs]\n",
    "    outs = model.prior_sample(pr_mat, c, sample_chd=False, sample_rhy=True, scale=1)\n",
    "    fn = os.path.join(folder, 'priorsample-' + info + '.mid')\n",
    "    track_notes = demo_maker.demo_format_convert([outs], outs_to_demo, bpm)\n",
    "    track_names = [str(i) for i in range(len(track_notes))]\n",
    "    demo_maker.write_demo(fn, track_notes, track_names, bpm, shift_beat=8)\n",
    "    \n",
    "    demo_folder = os.path.join(folder, info)\n",
    "    if not os.path.exists(demo_folder):\n",
    "        os.mkdir(demo_folder)\n",
    "    \n",
    "    fn = os.path.join(demo_folder, 'all.mid')\n",
    "    demo_maker.write_demo(fn, track_notes, track_names, bpm, shift_beat=8)\n",
    "    for name, track in zip(track_names, [outs]):\n",
    "        track_notes = demo_maker.demo_format_convert([track], outs_to_demo, bpm)\n",
    "        fn = os.path.join(demo_folder, name + '.mid')\n",
    "        track_names = ['sample']\n",
    "        demo_maker.write_demo(fn, track_notes, track_names, bpm, shift_beat=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_long_path = os.path.join(demo_path, 'prior_long')\n",
    "prior_long_path = os.path.join(demo_path, 'prior_long_ismir')\n",
    "if not os.path.exists(prior_long_path):\n",
    "    os.mkdir(prior_long_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2020)  # 1234 # 1434  # 2020\n",
    "# chord1 = ['C'] * 2 + ['A:min'] * 2 + ['F'] * 2 + ['G'] * 2\n",
    "chord2 = ['G'] * 2 + ['F'] * 2 + ['Eb'] * 4\n",
    "chord2 = ['F'] * 4 + ['Bb'] * 2 + ['F'] * 2\n",
    "prior_sample_song(*song1, chord2, 8, prior_long_path, '1564')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1234: 60\n",
    "\n",
    "234: 40\n",
    "\n",
    "1234, 1.2scale: 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior chord experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_sample_song(dataset_id, song_id, length, shift, bs=8, folder=None):\n",
    "    length = song_datasets.valid_length(dataset_id, song_id, length)\n",
    "    info = song_datasets.get_msg(dataset_id, song_id, length, shift)\n",
    "    batch = song_datasets.get_song_batch(dataset_id, song_id, length, shift)\n",
    "    x, c, pr_mat, dt_x = data_loaders.batch_to_inputs(batch)\n",
    "    pr_mat = pr_mat[1].unsqueeze(0).repeat(bs, 1, 1)\n",
    "    # pr_mat = pr_mat[0: bs]\n",
    "    outs = model.prior_sample(pr_mat, c, sample_chd=True, sample_rhy=False, scale=1)\n",
    "    fn = os.path.join(folder, 'prior_chdsample-' + info + '.mid')\n",
    "    track_notes = demo_maker.demo_format_convert([outs], outs_to_demo, bpm)\n",
    "    track_names = [str(i) for i in range(len(track_notes))]\n",
    "    demo_maker.write_demo(fn, track_notes, track_names, bpm, shift_beat=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "chdprior_long_path = os.path.join(demo_path, 'chd_prior_long')\n",
    "if not os.path.exists(chdprior_long_path):\n",
    "    os.mkdir(chdprior_long_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "prior_sample_song(*song2, 8, chdprior_long_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chord Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chord_interp_song(dataset_id, song_id, length, shift, chord1, chord2, bs=8, folder=None):\n",
    "    length = song_datasets.valid_length(dataset_id, song_id, length)\n",
    "    info = song_datasets.get_msg(dataset_id, song_id, length, shift)\n",
    "    batch = song_datasets.get_song_batch(dataset_id, song_id, length, shift)\n",
    "    x, c, pr_mat, dt_x = data_loaders.batch_to_inputs(batch)\n",
    "    c1 = torch.from_numpy(chord_label_to_input(chord1)).unsqueeze(0).repeat(bs, 1, 1).float()\n",
    "    c2 = torch.from_numpy(chord_label_to_input(chord2)).unsqueeze(0).repeat(bs, 1, 1).float()\n",
    "    pr_mat = pr_mat[0: bs]\n",
    "    outs = model.interp(pr_mat, c1, pr_mat, c2, interp_chd=True, interp_rhy=False, int_count=16)\n",
    "    fn = os.path.join(folder, 'interpsample-' + info + '.mid')\n",
    "    track_notes = demo_maker.demo_format_convert(outs, outs_to_demo, bpm)\n",
    "    track_names = [str(i) for i in range(len(track_notes))]\n",
    "    demo_maker.write_demo(fn, track_notes, track_names, bpm, shift_beat=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_path = os.path.join(demo_path, 'interp_path')\n",
    "interp_path = os.path.join(demo_path, 'interp_path_ismir')\n",
    "if not os.path.exists(interp_path):\n",
    "    os.mkdir(interp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chord1 = ['D:min7'] * 2 + ['G:7'] * 2 + ['C:maj7'] * 4\n",
    "# chord2 = ['F:min7'] * 2 + ['Bb:7'] * 2 + ['Eb:maj7'] * 4\n",
    "\n",
    "# chord1 = ['G'] * 4 + ['C'] * 4\n",
    "# chord2 = ['Eb'] * 4 + ['Ab'] * 4\n",
    "\n",
    "chord1 = ['C'] * 2 + ['A:min'] * 2 + ['F'] * 2 + ['G'] * 2\n",
    "chord2 = ['Eb'] * 2 + ['C:min'] * 2 + ['Ab'] * 2 + ['Bb'] * 2\n",
    "\n",
    "chord1 = ['Db'] * 2 + ['G'] * 2 + ['C:min'] * 4 #  + ['C'] * 2\n",
    "chord2 = ['C'] * 2 + ['D'] * 2 + ['G'] * 4\n",
    "# chord2 = ['F#'] * 2 + ['D#:min'] * 2 + ['B'] * 2 + ['C#'] * 2\n",
    "# chord2 = ['E:min7'] * 2 + ['A:7'] * 2 + ['D:min7', 'G:7'] + ['C:maj7'] * 2\n",
    "\n",
    "# chord2 = ['A:min'] * 2 + ['G'] * 2 + ['F', 'G'] + ['C'] * 2\n",
    "# chord1 = ['C'] * 2 + ['A:min'] * 2 + ['F'] * 2 + ['G'] * 2\n",
    "# chord2 = ['C#'] * 2 + ['A#:min'] * 2 + ['F#'] * 2 + ['G#'] * 2\n",
    "song_interp = [1, 26, 16, 6]\n",
    "chord_interp_song(*song_interp, chord1, chord2, 1, interp_path)  # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_chords = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "major_chords = ['C', 'G', 'D', 'A', 'E', 'B', 'F#', 'C#', 'G#', 'D#', 'A#', 'F']\n",
    "c = torch.from_numpy(chord_label_to_input(major_chords)).unsqueeze(1).repeat(1, 8, 1)\n",
    "c = c.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = model.chd_encoder(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = zs.mean.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 256)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2).fit_transform(z)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c2811f9d0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=[(0.1, 0.2, 0.5, a) for a in list(np.linspace(0, 1, 12))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.08333333,  0.16666667,  0.25      ,  0.33333333,\n",
       "        0.41666667,  0.5       ,  0.58333333,  0.66666667,  0.75      ,\n",
       "        0.83333333,  0.91666667,  1.        ,  1.08333333,  1.16666667,\n",
       "        1.25      ,  1.33333333,  1.41666667,  1.5       ,  1.58333333,\n",
       "        1.66666667,  1.75      ,  1.83333333,  1.91666667,  2.        ,\n",
       "        2.08333333,  2.16666667,  2.25      ,  2.33333333,  2.41666667,\n",
       "        2.5       ,  2.58333333,  2.66666667,  2.75      ,  2.83333333,\n",
       "        2.91666667,  3.        ,  3.08333333,  3.16666667,  3.25      ,\n",
       "        3.33333333,  3.41666667,  3.5       ,  3.58333333,  3.66666667,\n",
       "        3.75      ,  3.83333333,  3.91666667,  4.        ,  4.08333333,\n",
       "        4.16666667,  4.25      ,  4.33333333,  4.41666667,  4.5       ,\n",
       "        4.58333333,  4.66666667,  4.75      ,  4.83333333,  4.91666667,\n",
       "        5.        ,  5.08333333,  5.16666667,  5.25      ,  5.33333333,\n",
       "        5.41666667,  5.5       ,  5.58333333,  5.66666667,  5.75      ,\n",
       "        5.83333333,  5.91666667,  6.        ,  6.08333333,  6.16666667,\n",
       "        6.25      ,  6.33333333,  6.41666667,  6.5       ,  6.58333333,\n",
       "        6.66666667,  6.75      ,  6.83333333,  6.91666667,  7.        ,\n",
       "        7.08333333,  7.16666667,  7.25      ,  7.33333333,  7.41666667,\n",
       "        7.5       ,  7.58333333,  7.66666667,  7.75      ,  7.83333333,\n",
       "        7.91666667,  8.        ,  8.08333333,  8.16666667,  8.25      ,\n",
       "        8.33333333,  8.41666667,  8.5       ,  8.58333333,  8.66666667,\n",
       "        8.75      ,  8.83333333,  8.91666667,  9.        ,  9.08333333,\n",
       "        9.16666667,  9.25      ,  9.33333333,  9.41666667,  9.5       ,\n",
       "        9.58333333,  9.66666667,  9.75      ,  9.83333333,  9.91666667,\n",
       "       10.        , 10.08333333, 10.16666667, 10.25      , 10.33333333,\n",
       "       10.41666667, 10.5       , 10.58333333, 10.66666667, 10.75      ,\n",
       "       10.83333333, 10.91666667, 11.        , 11.08333333, 11.16666667,\n",
       "       11.25      , 11.33333333, 11.41666667, 11.5       , 11.58333333,\n",
       "       11.66666667, 11.75      , 11.83333333, 11.91666667])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 12, 1 / 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256])\n"
     ]
    }
   ],
   "source": [
    "chord1 = ['C'] * 2 + ['A:min'] * 2 + ['F'] * 2 + ['G'] * 2\n",
    "chord2 = ['Eb'] * 2 + ['C:min'] * 2 + ['Ab'] * 2 + ['Bb'] * 2\n",
    "chord0 = ['C'] * 8\n",
    "c1 = torch.from_numpy(chord_label_to_input(chord1)).unsqueeze(0).repeat(1, 1, 1).float()\n",
    "c2 = torch.from_numpy(chord_label_to_input(chord2)).unsqueeze(0).repeat(1, 1, 1).float()\n",
    "c0 = torch.from_numpy(chord_label_to_input(chord0)).unsqueeze(0).repeat(1, 1, 1).float()\n",
    "cs = torch.cat([c0, c1, c2], dim=0)\n",
    "with torch.no_grad():\n",
    "    zcs = model.chd_encoder(cs).mean\n",
    "print(zcs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "zc3 = (zcs[0] - zcs[1]) + zcs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "zc3 = zc3.unsqueeze(0)\n",
    "out = model.chd_decoder(zc3, True, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "root, chroma, bass = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 3, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(root.max(-1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0],\n",
      "         [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0],\n",
      "         [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0],\n",
      "         [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
      "         [1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0]]])\n"
     ]
    }
   ],
   "source": [
    "print(chroma.max(-1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
